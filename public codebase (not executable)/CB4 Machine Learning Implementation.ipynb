{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codebase 4: Machine Learning Implementation\n",
    "\n",
    "Implementation is structured in the following parts where sections 1 to 6 comprise cross-validation.\n",
    "\n",
    "1. Helper functions\n",
    "2. Undersampling\n",
    "3. Oversampling\n",
    "4. Weight Class\n",
    "5. Threshhold Testing \n",
    "6. Ensembles\n",
    "7. Create Financial Ratio Features Target Matrix\n",
    "8. Generate Holdout Testing Sets\n",
    "9. Test Holdout Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Helper Functions\n",
    "\n",
    "There are four key helper functions in implementation: (i) time equalization preprocesses the sample to ensure that the annual ratio of events in the majority and minority classes are equal, (ii) undersampling, (iii) oversampling and (iv) a function to convert sparse dataframes to sparse matrices in chunks.\n",
    "\n",
    "First up is time equalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize_year_ratio(df_train, ratio):\n",
    "    '''preprocesses sample to set the annual ratio of negative events (majority class) \n",
    "    equal to that of positive events (minority class)'''\n",
    "    \n",
    "    mask_pos = df_train['max_dd_1yr'] < -0.8\n",
    "    df_year = df_train[['ticker_','Filed_Date']][mask_pos]\n",
    "    df_year['year'] = df_year['Filed_Date'].dt.year\n",
    "    df_pos_count = df_year['year'].value_counts()\n",
    "    \n",
    "    years = sorted(df_pos_count.index.tolist())\n",
    "    \n",
    "    df_train['year'] = df_train['Filed_Date'].dt.year\n",
    "    \n",
    "    #loop through years and randomly select n samples\n",
    "    count=0\n",
    "    for year in years:\n",
    "    \n",
    "        mask_year = df_train['year']==year\n",
    "        df = df_train[mask_year]\n",
    "        mask_neg = df['max_dd_1yr'] >=-0.8\n",
    "        df = df[mask_neg]\n",
    "        m = df.shape[0]\n",
    "        n = int(ratio*df_pos_count[year])\n",
    "    \n",
    "        random_idx = random.sample(range(0,m), n)\n",
    "        df = df.iloc[random_idx]\n",
    "        if count == 0:\n",
    "            df_final = df\n",
    "        else:\n",
    "            df_final = pd.concat([df_final,df])\n",
    "        count +=1    \n",
    "    \n",
    "    df_train = df_train.drop('year', axis=1)\n",
    "    df_neg = df_final.drop('year', axis=1)\n",
    "    df_pos = df_train[mask_pos]\n",
    "    \n",
    "    df_train = pd.concat([df_neg, df_pos])\n",
    "    df_train = df_train.sort_values(by='Filed_Date')  \n",
    "\n",
    "    return df_train          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersample_random(X_train, y_train, seed = 41):\n",
    "    '''undersample negative events (majority class) to same size\n",
    "    as positive events (minority class)'''\n",
    "    \n",
    "    random.seed(seed)\n",
    "\n",
    "    #get indices and calculate class sizes\n",
    "    idx_train_argsort= np.argsort(y_train)\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = y_train.shape[0] - n_pos\n",
    "    n_min = min(n_pos, n_neg)\n",
    "    \n",
    "    #set minority class sets\n",
    "    idx_pos_prelim = idx_train_argsort[-n_pos:]\n",
    "    random_idx_pos = random.sample(range(0,n_pos), n_min)\n",
    "    idx_pos = idx_pos_prelim[random_idx_pos]\n",
    "    X_train_pos = X_train[idx_pos]\n",
    "    y_train_pos = y_train[idx_pos]\n",
    "    \n",
    "    #undersample majority class without replacement\n",
    "    idx_neg_prelim = idx_train_argsort[:n_neg]\n",
    "    random_idx_neg = random.sample(range(0,n_neg), n_min)\n",
    "    idx_neg = idx_neg_prelim[random_idx_neg]\n",
    "    X_train_neg = X_train[idx_neg]\n",
    "    y_train_neg = y_train[idx_neg]\n",
    "\n",
    "    #join classes for training and testing sets \n",
    "    X_train_balanced = vstack((X_train_pos,X_train_neg))        #X arrays assumed sparse\n",
    "    y_train_balanced = np.concatenate((y_train_pos,y_train_neg), axis=0)  \n",
    "    \n",
    "    dict_answer = {'X_balanced': X_train_balanced , 'y_balanced': y_train_balanced}\n",
    "    \n",
    "    return dict_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and Oversampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_random(X_train, y_train, seed = 41, flag=False, n='define'):\n",
    "    '''oversmaple positive events (minority class) to same size\n",
    "    as negative events (majority class)'''\n",
    "    \n",
    "    random.seed(seed)\n",
    "    \n",
    "    #get indices and calculate class sizes\n",
    "    idx_train_argsort= np.argsort(y_train)\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = y_train.shape[0] - n_pos\n",
    "    \n",
    "    #Default to size of largest sample unless set in argument\n",
    "    if flag==True:\n",
    "        n_max = n\n",
    "    else:  \n",
    "        n_max = max(n_pos, n_neg)\n",
    "    \n",
    "    #oversample minority class with replacement\n",
    "    idx_pos_prelim = idx_train_argsort[-n_pos:]\n",
    "    random_idx_pos = np.random.choice(range(0,n_pos), n_max)\n",
    "    idx_pos = idx_pos_prelim[random_idx_pos]\n",
    "    X_train_pos = X_train[idx_pos]\n",
    "    y_train_pos = y_train[idx_pos]\n",
    "    \n",
    "    #randomly sample majority class without replacement to required size\n",
    "    idx_neg_prelim = idx_train_argsort[:n_neg]\n",
    "    random_idx_neg = random.sample(range(0,n_neg), n_max)\n",
    "    idx_neg = idx_neg_prelim[random_idx_neg]\n",
    "    X_train_neg = X_train[idx_neg]\n",
    "    y_train_neg = y_train[idx_neg]\n",
    "\n",
    "    #join classes for training and testing sets \n",
    "    try:\n",
    "        X_train_balanced = vstack((X_train_pos,X_train_neg))     #if X arrays sparse\n",
    "    except:\n",
    "        X_train_balanced = np.concatenate((X_train_pos,X_train_neg), axis=0)\n",
    "        \n",
    "    y_train_balanced = np.concatenate((y_train_pos,y_train_neg), axis=0)\n",
    "    \n",
    "    dict_answer = {'X_balanced': X_train_balanced , 'y_balanced': y_train_balanced}\n",
    "    \n",
    "    return dict_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting sparse dataframe to sparse matrix in chunks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_values_csc_chunk(df):\n",
    "    '''converts dataframe to sparse matrix in chunks'''\n",
    "    \n",
    "    #calculate number loops for 3,000 chunk size\n",
    "    rows = df.shape[0]\n",
    "    if rows < 3000:\n",
    "        num = rows - 1\n",
    "    else:\n",
    "        num = 3000\n",
    "        \n",
    "    loops = rows // num\n",
    "    stub_start = num * loops \n",
    "\n",
    "    #process loops    \n",
    "    for j in range(1, 1+ loops):\n",
    "        arr = df[(j-1)*num: j*num].values\n",
    "        arr = np.nan_to_num(arr)\n",
    "        mat_csr = csr_matrix(arr)\n",
    "        if j == 1:\n",
    "            answer = mat_csr\n",
    "        else:\n",
    "            answer =  vstack([answer, mat_csr])\n",
    "    \n",
    "    #process end stub        \n",
    "    arr_stub = df[stub_start:].values\n",
    "    arr_stub = np.nan_to_num(arr_stub)    \n",
    "    mat_csr_stub = csr_matrix(arr_stub)\n",
    "    \n",
    "    #join stub to rest\n",
    "    answer =  vstack([answer, mat_csr_stub])\n",
    "                \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the method with least computation, undersampling is where we do the heavy lifting to find the core model. This is where we choose min_df, decide on random or time equalized sampling and investigate whther sector dummy variables improve the model.\n",
    "\n",
    "We start with choosing min_df by looking at performance over a random selection of samples for various min_df values:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "\n",
    "#inputs\n",
    "label_cv = ['cv1', 'cv2', 'cv3', 'cv4']   #['cv1', 'cv2', 'cv3', 'cv4']\n",
    "vector_func = 'TfidfVectorizer'\n",
    "ngram = 'unigram'\n",
    "min_df = 25\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "models = [GradientBoostingClassifier(random_state=41),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt'),\n",
    "          LogisticRegression(random_state=41)]\n",
    "method = 'undersample_random'     #describes methof for output name\n",
    "model_names = ['grad_boost', 'random_forest', 'log_reg' ]\n",
    "output_filename= 'dict_cv_' + method +'_' + vector_func + '_' + 'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "\n",
    "#calculations\n",
    "\n",
    "dict_cv= {}\n",
    "\n",
    "for label in label_cv:\n",
    "    \n",
    "    print(label)\n",
    "    \n",
    "    #open dataframe files for cv set\n",
    "    dict_cv[label] = {}\n",
    "    filename = label + '_' + vector_func +  '_' +'min_df_' + str(min_df) + '_' + ngram + '.pickle' \n",
    "    d_cv = pd.read_pickle(filename)\n",
    "    df_train = d_cv['min_df_' + str(min_df)]['df_train_master']\n",
    "    df_test = d_cv['min_df_' + str(min_df)]['df_test_master']\n",
    "    \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    #convert to X and Y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    y_test = df_y_test.values\n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing)\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "    \n",
    "    #undersample\n",
    "    dict_bal = undersample_random(X_train, y_train, seed = 41)\n",
    "    X_train_balanced = dict_bal['X_balanced']\n",
    "    y_train_balanced = dict_bal['y_balanced'] \n",
    "    \n",
    "    #train model\n",
    "    for idx, model_func in enumerate(models):\n",
    "        model_name = model_names[idx]\n",
    "        model =model_func\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        dict_cv[label][model_name] = {'y_test': y_test, 'y_pred': y_pred,\n",
    "                                      'y_proba': y_proba, 'conf_matrix':cm,\n",
    "                                      'class_report': report, \n",
    "                                      'macro_recall':recall}\n",
    "        \n",
    "        print(model_name, ' : ', \"{:.2f}\".format(recall))\n",
    "    \n",
    "    with open(output_filename, 'wb') as handle:                                     \n",
    "        pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before considering time-equalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "\n",
    "#inputs\n",
    "ratio = 5\n",
    "label_cv = ['cv1', 'cv2', 'cv3', 'cv4']   #['cv1', 'cv2', 'cv3', 'cv4']\n",
    "vector_func = 'TfidfVectorizer'\n",
    "ngram = 'unigram'\n",
    "min_df = 25\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "\n",
    "models = [GradientBoostingClassifier(random_state=41),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt'),\n",
    "          LogisticRegression(random_state=41)]\n",
    "method = 'undersample_equal_num'\n",
    "model_names = ['grad_boost', 'random_forest', 'log_reg' ]\n",
    "output_filename= 'dict_cv_' + method +'_' + vector_func + '_' + 'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "\n",
    "#calculations\n",
    "dict_cv= {}\n",
    "\n",
    "for label in label_cv:\n",
    "    \n",
    "    print(label)\n",
    "    #open dataframe files for cv set\n",
    "    dict_cv[label] = {}\n",
    "    filename = label + '_' + vector_func +  '_' +'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "    d_cv = pd.read_pickle(filename) \n",
    "    df_train = d_cv['min_df_' + str(min_df)]['df_train_master']\n",
    "    df_test = d_cv['min_df_' + str(min_df)]['df_test_master']\n",
    "    \n",
    "    #equal number algo\n",
    "    df_train = equalize_year_ratio(df_train, ratio)\n",
    "        \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1 \n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    #convert to X and Y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    y_test = df_y_test.values\n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing)\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "    \n",
    "    #undersample\n",
    "    dict_bal = undersample_random(X_train, y_train, seed = 41)\n",
    "    X_train_balanced = dict_bal['X_balanced']\n",
    "    y_train_balanced = dict_bal['y_balanced'] \n",
    "    \n",
    "    #train model\n",
    "    for idx, model_func in enumerate(models):\n",
    "        model_name = model_names[idx]\n",
    "        model =model_func\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        dict_cv[label][model_name] = {'y_test': y_test, 'y_pred': y_pred,\n",
    "                                      'y_proba': y_proba, 'conf_matrix':cm,\n",
    "                                      'class_report': report, \n",
    "                                      'macro_recall':recall}\n",
    "        \n",
    "        print(model_name, ' : ', \"{:.2f}\".format(recall))\n",
    "    \n",
    "    with open(output_filename, 'wb') as handle:                                     \n",
    "        pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sector dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "\n",
    "#inputs\n",
    "ratio = 5\n",
    "label_cv = ['cv1', 'cv2', 'cv3', 'cv4']   #['cv1', 'cv2', 'cv3', 'cv4']\n",
    "vector_func = 'TfidfVectorizer'\n",
    "ngram = 'unigram'\n",
    "min_df = 25\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "models = [GradientBoostingClassifier(random_state=41),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt'),\n",
    "          LogisticRegression(random_state=41)]\n",
    "method = 'undersample_equal_num_DUMMIES'\n",
    "model_names = ['grad_boost', 'random_forest', 'log_reg' ]\n",
    "\n",
    "output_filename= 'dict_cv_' + method +'_' + vector_func + '_' + 'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "\n",
    "#calculations\n",
    "dict_cv= {}\n",
    "\n",
    "for label in label_cv:\n",
    "    \n",
    "    print(label)\n",
    "    #open dataframe files for cv set\n",
    "    dict_cv[label] = {}\n",
    "    filename = label + '_' + vector_func +  '_' +'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "    d_cv = pd.read_pickle(filename)\n",
    "    df_train = d_cv['min_df_' + str(min_df)]['df_train_master']\n",
    "    df_test = d_cv['min_df_' + str(min_df)]['df_test_master']\n",
    "   \n",
    "    #equal number algo\n",
    "    df_train = equalize_year_ratio(df_train, ratio)\n",
    "    \n",
    "    #get_dummies\n",
    "    df_dummies_train = pd.get_dummies(df_train['sector_'], prefix='_').astype(int)\n",
    "    df_dummies_test = pd.get_dummies(df_test['sector_'], prefix='_').astype(int)\n",
    "    #make sure they have same columns\n",
    "    dummies_train = set(df_dummies_train.columns)\n",
    "    dummies_test = set(df_dummies_test.columns)\n",
    "    union_dummies = dummies_train.union(dummies_test)\n",
    "    add_dummies_train = union_dummies - dummies_train\n",
    "    add_dummies_test = union_dummies - dummies_test\n",
    "    #make sure train and test sets have same number cols    \n",
    "    if len(add_dummies_train) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for dummy in add_dummies_train:\n",
    "            df_dummies_train[dummy] = 0\n",
    "            \n",
    "    if len(add_dummies_test) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        for dummy in add_dummies_test:\n",
    "            df_dummies_test[dummy] = 0\n",
    "    #convert to sparse matrices\n",
    "    csr_dummies_train = csr_matrix(df_dummies_train.values)\n",
    "    csr_dummies_test = csr_matrix(df_dummies_test.values)\n",
    "    \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "    \n",
    "    #convert to X and Y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    X_train = hstack((X_train, csr_dummies_train))\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    X_test = hstack((X_test, csr_dummies_test))\n",
    "    y_test = df_y_test.values\n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing)\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "    \n",
    "    #undersample\n",
    "    dict_bal = undersample_random(X_train, y_train, seed = 41)\n",
    "    X_train_balanced = dict_bal['X_balanced']\n",
    "    y_train_balanced = dict_bal['y_balanced'] \n",
    "    \n",
    "    #train model\n",
    "    for idx, model_func in enumerate(models):\n",
    "        model_name = model_names[idx]\n",
    "        model =model_func\n",
    "        model.fit(X_train_balanced, y_train_balanced)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "         ort': report, \n",
    "                                      'macro_recall':recall}\n",
    "        \n",
    "        print(model_name, ' : ', \"{:.2f}\".format(recall))\n",
    "    \n",
    "    with open(output_filename, 'wb') as handle:                                     \n",
    "        pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Oversampling\n",
    "\n",
    "We apply the core model (min_df=25, time equalization and no sectordummy variables) to oversampling. Given the 1:20 data imbalance, we test a more computationally practical n = 2,3 and 5 where n x (minority class size for unique events) sets the size of the samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "\n",
    "#inputs\n",
    "pd.set_option('mode.chained_assignment', None)  \n",
    "ratio = 5\n",
    "label_cv = ['cv1', 'cv2', 'cv3', 'cv4']  #['cv1', 'cv2', 'cv3', 'cv4']\n",
    "vector_func = 'TfidfVectorizer'\n",
    "ngram = 'unigram'\n",
    "min_df = 25\n",
    "over_sample_amount = [2, 3, 5]\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "models = [GradientBoostingClassifier(random_state=41),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt'),\n",
    "          LogisticRegression(random_state=41), MultinomialNB()]\n",
    "method = 'oversample_equal_num'\n",
    "model_names = ['grad_boost', 'random_forest', 'log_reg', 'NBayes' ]\n",
    "\n",
    "\n",
    "#create dictionary structure\n",
    "dict_cv = {}\n",
    "for label in label_cv:\n",
    "    dict_cv.update({label: {}})\n",
    "    for number in over_sample_amount:\n",
    "        dict_cv[label].update({'number'+ str(number):{}})\n",
    "        for model in model_names:\n",
    "            dict_cv[label]['number'+ str(number)].update({model: {}})\n",
    "\n",
    "\n",
    "for label in label_cv:\n",
    "    \n",
    "    print(label)\n",
    "    #open dataframe files for cv set\n",
    "    filename = label + '_' + vector_func +  '_' +'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "    d_cv = pd.read_pickle(filename)\n",
    "    df_train = d_cv['min_df_' + str(min_df)]['df_train_master']\n",
    "    df_test = d_cv['min_df_' + str(min_df)]['df_test_master']\n",
    "    \n",
    "    #Equal number algo\n",
    "    df_train = equalize_year_ratio(df_train, ratio)\n",
    "    \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_2yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_2yr'] <= -0.8)*1\n",
    "\n",
    "    #convert to X and Y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    y_test = df_y_test.values  \n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing)\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "    \n",
    "    #oversample\n",
    "    for number in over_sample_amount:\n",
    "        \n",
    "        key_number = 'number'+ str(number)  \n",
    "        n = int(number*n_pos)\n",
    "        \n",
    "        dict_bal = oversample_random(X_train, y_train, seed = 41, flag=True, n=n)\n",
    "        X_train_balanced = dict_bal['X_balanced']\n",
    "        y_train_balanced = dict_bal['y_balanced'] \n",
    "\n",
    "        #train model\n",
    "        for idx, model_func in enumerate(models):\n",
    "            model_name = model_names[idx]\n",
    "            model =model_func\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            y_pred = model.predict(X_test)\n",
    "            y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            report = classification_report(y_test, y_pred,output_dict=True)\n",
    "            recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "            dict_cv[label][key_number][model_name] = {'y_test': y_test, 'y_pred': y_pred,\n",
    "                                      'y_proba': y_proba, 'conf_matrix':cm,\n",
    "                                      'class_report': report, \n",
    "                                      'macro_recall':recall}\n",
    "        \n",
    "            print(model_name, ' : ', \"{:.2f}\".format(recall))\n",
    "            \n",
    "           \n",
    "output_filename= 'dict_cv_' + method +'_' + vector_func + '_' + 'min_df_' + str(min_df) + '_number_ratios_' + ngram + '.pickle'\n",
    "with open(output_filename, 'wb') as handle:                                     \n",
    "    pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Weight Classes\n",
    "\n",
    "We use SK-Learn's Random Forest to see how balanced weight class performs for the problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import csr_matrix, vstack, hstack\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "#inputs\n",
    "ratio = 5\n",
    "label_cv = ['cv1', 'cv2', 'cv3', 'cv4'] #['cv1', 'cv2', 'cv3', 'cv4']\n",
    "vector_func = 'TfidfVectorizer'  \n",
    "ngram = 'unigram'\n",
    "min_df = 25\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "models = [GradientBoostingClassifier(random_state=41),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt'),\n",
    "          RandomForestClassifier(n_estimators=100, bootstrap = True, \n",
    "                                 max_features = 'sqrt', class_weight='balanced')]\n",
    "method = 'class_weights_equal_num'\n",
    "model_names = ['grad_boost', 'random_forest_balanced_cw_none',\n",
    "                                           'random_forest_cw_balanced']\n",
    "output_filename= 'dict_cv_' + method +'_' + vector_func + '_' + 'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "\n",
    "#calculations\n",
    "dict_cv= {}\n",
    "\n",
    "for label in label_cv:\n",
    "    \n",
    "    print(label)\n",
    "    #open dataframe files for cv set\n",
    "    dict_cv[label] = {}\n",
    "    filename = label + '_' + vector_func +  '_' +'min_df_' + str(min_df) + '_' + ngram + '.pickle'\n",
    "    d_cv = pd.read_pickle(filename)\n",
    "    df_train = d_cv['min_df_' + str(min_df)]['df_train_master']\n",
    "    df_test = d_cv['min_df_' + str(min_df)]['df_test_master']\n",
    "    \n",
    "    #equal number algo\n",
    "    df_train = equalize_year_ratio(df_train, ratio)\n",
    "    \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    #convert to X and Y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    y_test = df_y_test.values\n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing)\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "    \n",
    "    #train model\n",
    "    for idx, model_func in enumerate(models):\n",
    "        model_name = model_names[idx]\n",
    "        model =model_func\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "    \n",
    "        cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "        report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        recall = recall_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        dict_cv[label][model_name] = {'y_test': y_test, 'y_pred': y_pred,\n",
    "                                      'y_proba': y_proba, 'conf_matrix':cm,\n",
    "                                      'class_report': report, \n",
    "                                      'macro_recall':recall}\n",
    "        \n",
    "        print(model_name, ' : ', \"{:.2f}\".format(recall))\n",
    "    \n",
    "    with open(output_filename, 'wb') as handle:                                     \n",
    "        pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Threshold Testing\n",
    "\n",
    "This section investigates how performance changes with movement of probability threshhold away from 50%.\n",
    "\n",
    "This analysis can be found in Code Base 4: Interactive Analysis and Interpretation where it uses the results saved in preceding sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Ensemble\n",
    "\n",
    "We investigate ensemble methods by (i) combining learning alogorithims for undersampling, (ii) combining learning algorithms for oversampling and (iii) combining the best models for vanilla oversampling and undersampling.\n",
    "\n",
    "This analysis can be found in Code Base 4: Interactive Analysis and Interpretation where it uses the results saved in preceding sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Create Financial Ratios Target-Features Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code matches tickers and filing dates of the NLP dataset and calculates the relevant annual financial ratios where there is data.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#inputs\n",
    "input_fin = 'fundamentals_df_all_db_ary.pickle'\n",
    "input_all_10ks = '10k_clean_df.pickle'\n",
    "input_master = 'dict_10k_matched_dd.pickle'\n",
    "output_file = \"df_fund_ratios_matched.pickle\"\n",
    "\n",
    "\n",
    "#Alignment calcs: reportperiod to filed date\n",
    "df_align = pd.read_pickle(input_all_10ks)\n",
    "df_align = df_align[['ticker','Period', 'Filed_Date']]\n",
    "df_align['Period'] = pd.to_datetime(df_align['Period'], errors='coerce').values\n",
    "df_align['Filed_Date'] = pd.to_datetime(df_align['Filed_Date'], errors='coerce').values\n",
    "df_align.columns = ['ticker_','reportperiod', 'Filed_Date']\n",
    "\n",
    "#Calculate Ratios\n",
    "df_fin= pd.read_pickle(input_fin)\n",
    "\n",
    "df_fin_ratios = pd.DataFrame(df_fin['reportperiod'])\n",
    "df_fin_ratios['ticker_'] = df_fin['ticker']\n",
    "\n",
    "df_fin_ratios['netinc_assets'] = df_fin['netinc'].values / df_fin['assets'].values\n",
    "df_fin_ratios['leverage_'] = df_fin['assets'].values / df_fin['liabilities'].values\n",
    "df_fin_ratios['accruals_'] = df_fin['ncfo'].values / df_fin['netinc'].values\n",
    "df_fin_ratios['cash_debt'] = df_fin['ncfo'].values / df_fin['liabilities'].values\n",
    "df_fin_ratios['coe_'] = df_fin['ncfo'].values / (df_fin['assets'] - df_fin['liabilities']).values\n",
    "df_fin_ratios['roe_'] = df_fin['netinc'].values / (df_fin['assets'] - df_fin['liabilities']).values\n",
    "\n",
    "del df_fin #memory management\n",
    "\n",
    "df_fin_ratios = df_fin_ratios.dropna()\n",
    "df_fin_ratios = df_fin_ratios.merge(df_align, on =['ticker_','reportperiod'], how='inner')\n",
    "df_fin_ratios = df_fin_ratios.drop('reportperiod', axis=1)\n",
    "df_fin_ratios = df_fin_ratios.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "#merge to NLP matched master tickers / dates\n",
    "dict_input = pd.read_pickle(input_master)       \n",
    "df = dict_input['matched_df_10k_dd']\n",
    "df = df[['ticker_', 'Filed_Date','sector', 'max_dd_1yr']].sort_values('Filed_Date')\n",
    "df.columns = ['ticker_', 'Filed_Date','sector_', 'max_dd_1yr']\n",
    "\n",
    "df = df.merge(df_fin_ratios, on=['ticker_', 'Filed_Date'], how='inner')\n",
    "\n",
    "with open(output_file, 'wb') as handle:                                     \n",
    "    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Generate Holdout Testing Sets\n",
    "\n",
    "This section starts by generating the holdout set before testing it with the optimal model found in CV (ensemble of oversmapling and undersampling). An expanding annual window method is used to update the model and test on an annual basis. The aggregation of these results then form the full set of holdout results.\n",
    "\n",
    "Generate holdout sets for NLP model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from capstone_10k_functions import vectorize_corpus\n",
    "from datetime import datetime as dt\n",
    "\n",
    "t1 = dt.now()\n",
    "print(t1)\n",
    "\n",
    "#inputs\n",
    "input_file = 'dict_10k_matched_dd.pickle'\n",
    "vector_func = TfidfVectorizer    \n",
    "func_name = 'TfidfVectorizer'   #['TfidfVectorizer', 'CountVectorizer']\n",
    "hold_out_set_start = [2015, 2016, 2017, 2018, 2019]\n",
    "min_df_grid = [25]\n",
    "max_df = 0.5\n",
    "ngram = (1,1)\n",
    "ngram_name = 'unigram'\n",
    "label = ['hold_out_2015', 'hold_out_2016', 'hold_out_2017', 'hold_out_2018', \n",
    "         'hold_out_2019']\n",
    "\n",
    "\n",
    "#read data into memory\n",
    "with open(input_file , 'rb') as f:\n",
    "        d_data = pickle.load(f)\n",
    "df = d_data['matched_df_10k_dd']\n",
    "df = df.sort_values(\"Filed_Date\")\n",
    "\n",
    "for idx_ho, year in enumerate(hold_out_set_start):\n",
    "    \n",
    "    print(label[idx_ho])\n",
    "    \n",
    "    ##Define hold out set\n",
    "    mask_train = df['Filed_Date'].dt.year < year\n",
    "    mask_test = df['Filed_Date'].dt.year == year\n",
    "    df_test = df[mask_test]\n",
    "    df_train = df[mask_train]\n",
    "\n",
    "    #Generate df master (word vector / vectorizer) sets for each cv fold\n",
    "    dict_cv = {}\n",
    "    #format training data\n",
    "    df_train_text = df_train[['ticker_','Filed_Date', 'Text']]\n",
    "    df_train_other = df_train.drop('Text', axis=1)\n",
    "    df_train_other.columns = ['ticker_', 'Filed_Date', 'sector_', 'sic_sector', \n",
    "                        'max_dd_1yr', 'max_dd_2yr', 'year_dd_flag', \n",
    "                        'cum_year_dd_flag']\n",
    "    df_train_other['custom_sector'] = str(df_train_other['sector_']) + ' : ' + str(df_train_other['sic_sector'])\n",
    "\n",
    "    #format testing data\n",
    "    df_test_text = df_test[['ticker_','Filed_Date', 'Text']]\n",
    "    df_test_other = df_test.drop('Text', axis=1)\n",
    "    df_test_other.columns = ['ticker_', 'Filed_Date', 'sector_', 'sic_sector', \n",
    "                        'max_dd_1yr', 'max_dd_2yr', 'year_dd_flag', \n",
    "                        'cum_year_dd_flag']\n",
    "    df_test_other['custom_sector'] = str(df_test_other['sector_']) + ' : ' + str(df_test_other['sic_sector'])\n",
    "        \n",
    "\n",
    "    for min_df in min_df_grid: \n",
    "        print(min_df)\n",
    "        \n",
    "        #name for cv dictionary specified by min_df value\n",
    "        key_name = 'min_df_' + str(min_df)\n",
    "        \n",
    "        #vectorize corpus and assign word vector and vectorizer\n",
    "        function = vectorize_corpus(df_train_text['Text'], vector_func, min_df, \n",
    "                                            max_df,ngram)\n",
    "        X = function['df_wv']\n",
    "        vectorizer = function['vectorizer']\n",
    "        \n",
    "        #Transform training data into df_master format\n",
    "        vocab = X.columns.tolist()\n",
    "        X['Filed_Date'] = df_train_text['Filed_Date'].values\n",
    "        X['ticker_'] = df_train_text['ticker_'].values\n",
    "                        \n",
    "        df_train_master = df_train_other.merge(X, on=['ticker_','Filed_Date'], how='inner')\n",
    "        \n",
    "        #Transform test data into df master format\n",
    "        arr_test_transform = vectorizer.transform(df_test_text['Text'])\n",
    "        df_test_transform = pd.DataFrame.sparse.from_spmatrix(arr_test_transform,\n",
    "                                                           columns = vocab)\n",
    "        df_test_transform['Filed_Date'] = df_test_text['Filed_Date'].values\n",
    "        df_test_transform['ticker_'] = df_test_text['ticker_'].values\n",
    "        \n",
    "        df_test_master = df_test_other.merge(df_test_transform, \n",
    "                                             on=['ticker_','Filed_Date'], \n",
    "                                                                 how='inner')\n",
    "            \n",
    "        dict_final = {'df_test_master': df_test_master, 'df_train_master': df_train_master}\n",
    "                \n",
    "        dict_cv[key_name] = dict_final\n",
    "        \n",
    "        output_filename = label[idx_ho] + '_' + func_name + '_' + key_name + '_' + ngram_name + '.pickle'\n",
    "           \n",
    "        with open(output_filename, 'wb') as handle:                                     \n",
    "            pickle.dump(dict_cv, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "                    \n",
    "t2 = dt.now()\n",
    "print(t2)\n",
    "print(t2-t1)\n",
    "\n",
    "#runtime 2hrs11mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate holdout sets for financial ratio (FIN) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "#inputs\n",
    "input_file = \"df_fund_ratios_matched.pickle\"\n",
    "output_filename = 'hold_out_fund_ratio_sets.pickle'\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "labels = list(map(lambda x: 'fund_h_out_' + str(x), years))\n",
    "\n",
    "#read data into memory and set new year_column\n",
    "df_all = pd.read_pickle(input_file)\n",
    "df_all['year_'] = (df_all['Filed_Date'].dt.year).values\n",
    "\n",
    "#create dictionary\n",
    "dict_sets={}\n",
    "for label in labels:\n",
    "    dict_sets.update({label: {'df_train_master': pd.DataFrame(),\n",
    "                              'df_test_master': pd.DataFrame()}}) \n",
    "    \n",
    "#Create holdout sets and populate dictionary \n",
    "for idx, label in enumerate(labels):\n",
    "    year = years[idx]\n",
    "    \n",
    "    mask_train = df_all['year_'] < year\n",
    "    mask_test = df_all['year_'] == year\n",
    "    \n",
    "    df_train = df_all[mask_train]\n",
    "    df_test = df_all[mask_test]\n",
    "    \n",
    "    dict_sets[label]['df_train_master'] = df_train\n",
    "    dict_sets[label]['df_test_master'] = df_test\n",
    "    \n",
    "with open(output_filename, 'wb') as handle:                                     \n",
    "    pickle.dump(dict_sets, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The holdout sets for the market (MKT) model are set equal to FIN holdout sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Test Holdout Sets \n",
    "\n",
    "Test and store results for the NLP model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from scipy.sparse import csr_matrix, vstack, hstack, identity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from capstone_10k_functions import convert_df_values_csc_chunk\n",
    "from datetime import datetime as dt\n",
    "\n",
    "t1 = dt.now()\n",
    "print(t1)\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "\n",
    "#inputs\n",
    "ratio = 5\n",
    "vector_func = 'TfidfVectorizer'\n",
    "ngram = 'unigram'\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "label_years = list(map(lambda x: 'hold_out_' + str(x), years))\n",
    "number = 3\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_', 'sic_sector', 'max_dd_1yr','max_dd_2yr', \n",
    "                  'year_dd_flag', 'cum_year_dd_flag', 'custom_sector']\n",
    "weight_over =0.25\n",
    "weight_under = 0.75\n",
    "model_over = GradientBoostingClassifier(random_state=41)\n",
    "model_under = GradientBoostingClassifier(random_state=41)\n",
    "method = 'over_under_ensemble_words_only_hold_out'\n",
    "\n",
    "#create dictionary structure\n",
    "dict_years = {}\n",
    "for label in label_years:\n",
    "    dict_years.update({label: {}})\n",
    "\n",
    "#loop through holdout sets and populate dictionary\n",
    "for label in label_years:\n",
    "    \n",
    "    print(label)\n",
    "    \n",
    "    filename = label + '_' + vector_func + '_min_df_25_' + ngram + '.pickle'\n",
    "    d_years = pd.read_pickle(filename)\n",
    "    df_train = d_years['min_df_25']['df_train_master']\n",
    "    df_test = d_years['min_df_25']['df_test_master']\n",
    "\n",
    "    #Equal number algo\n",
    "    df_train = equalize_year_ratio(df_train, ratio)\n",
    "       \n",
    "    #define X and y dataframes \n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    \n",
    "    #convert X and y arrays\n",
    "    X_train = convert_df_values_csc_chunk(df_x_train)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = convert_df_values_csc_chunk(df_x_test)\n",
    "    y_test = df_y_test.values  \n",
    "\n",
    "    #normalize (row wise so not strictly necesarry to process this way\n",
    "    #but kept in format for generalization to other preprocessing\n",
    "    n_test = y_test.shape[0]\n",
    "    X_train_test = vstack((X_train, X_test ))\n",
    "    X_train = normalize(X_train)\n",
    "    X_test = normalize(X_train_test)[-n_test:]    \n",
    "\n",
    "    #oversample              \n",
    "    key_number = 'number'+ str(number)\n",
    "    n_over = int(number*n_pos_over)\n",
    "    dict_bal_over = oversample_random(X_train, y_train, seed = 41, flag=True, n=n_over)\n",
    "    X_train_balanced_over = dict_bal_over['X_balanced'] \n",
    "    y_train_balanced_over = dict_bal_over['y_balanced']  \n",
    "\n",
    "    #undersample\n",
    "    dict_bal_under = undersample_random(X_train, y_train, seed = 41)\n",
    "    X_train_balanced_under = dict_bal_under['X_balanced'] \n",
    "    y_train_balanced_under = dict_bal_under['y_balanced']  \n",
    "\n",
    "    #train model\n",
    "    model_1 =model_over\n",
    "    model_1.fit(X_train_balanced_over, y_train_balanced_over)\n",
    "    y_1_log_proba = model_1.predict_log_proba(X_test)[:,1]\n",
    "        \n",
    "    model_2 =model_under\n",
    "    model_2.fit(X_train_balanced_under, y_train_balanced_under)\n",
    "    y_2_log_proba = model_2.predict_log_proba(X_test)[:,1]\n",
    "        \n",
    "    y_log_proba = weight_over*y_1_log_proba + weight_under*y_2_log_proba\n",
    "    y_pred = (y_log_proba > np.log(0.5))*1\n",
    "        \n",
    "    #calcuate model metrics    \n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    pos_recall = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "    neg_recall = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "    mh_recall =  2*neg_recall*pos_recall / (neg_recall + pos_recall)\n",
    "    report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        \n",
    "    print('mh_recall = ', mh_recall)\n",
    "    print('pos_recall = ', pos_recall)\n",
    "    print('neg_recall = ', neg_recall)\n",
    "        \n",
    "    df_y_result = df_test[['ticker_', 'Filed_Date']]\n",
    "    df_y_result['true_'] = y_test\n",
    "    df_y_result['pred_'] = y_pred\n",
    "    df_y_result['log_proba'] = y_log_proba\n",
    "        \n",
    "    dict_years[label] = {'df_y_result': df_y_result, 'class_report': report}\n",
    "        \n",
    "        \n",
    "    #find words in testing set only and count doc number\n",
    "          #drop null columns\n",
    "    null_columns = df_x_test.columns[df_x_test.isnull().any()]\n",
    "    df_x_test_notna = df_x_test.drop(null_columns, axis=1)\n",
    "          #count how many docs word in\n",
    "    df_x_test_notna = df_x_test_notna.transpose()\n",
    "    s_word_in_test_doc_count = df_x_test_notna.apply(lambda x: (x != 0).sum(), axis=1) \n",
    "    mask_keep = s_word_in_test_doc_count != 0\n",
    "    s_word_in_test_doc_count = s_word_in_test_doc_count[mask_keep]\n",
    "    s_word_in_test_doc_count = s_word_in_test_doc_count.sort_values(ascending=False)\n",
    "\n",
    "        #find words in predicted pos only only\n",
    "    mask_pred_pos = (y_pred == 1)\n",
    "    df_x_pred_pos = df_x_test[mask_pred_pos]\n",
    "          #drop null columns\n",
    "    null_columns = df_x_pred_pos.columns[df_x_pred_pos.isnull().any()]\n",
    "    df_x_pred_pos_notna = df_x_pred_pos.drop(null_columns, axis=1)\n",
    "          #count how many docs word in\n",
    "    df_x_pred_pos_notna= df_x_pred_pos_notna.transpose()\n",
    "    s_word_in_pred_pos_doc_count = df_x_pred_pos_notna.apply(lambda x: (x != 0).sum(), axis=1) \n",
    "    mask_keep = s_word_in_pred_pos_doc_count!= 0\n",
    "    s_word_in_pred_pos_doc_count = s_word_in_pred_pos_doc_count[mask_keep]   \n",
    "    s_word_in_pred_pos_doc_count = s_word_in_pred_pos_doc_count.sort_values(ascending=False)\n",
    "        \n",
    "\n",
    "    #Generate prob word matrix \n",
    "    words_list = list(df_x_test.columns)  \n",
    "    n_id = len(words_list)\n",
    "\n",
    "    word_arr = identity(n_id).tolil()\n",
    "    word_arr_q = csr_matrix(word_arr)\n",
    "            \n",
    "    word_1_log_proba = model_1.predict_log_proba(word_arr_q)[:,1]\n",
    "    word_2_log_proba = model_2.predict_log_proba(word_arr_q)[:,1]\n",
    "    word_log_proba = weight_over*word_1_log_proba + weight_under*word_2_log_proba\n",
    "    word_proba = np.exp(word_log_proba)\n",
    "\n",
    "    df_words_prob = pd.DataFrame(word_proba, index = words_list, columns=['prob'])\n",
    "    df_words_prob = df_words_prob.sort_values('prob', ascending=False)\n",
    "        \n",
    "    dict_years[label] = {'df_y_result': df_y_result,\n",
    "                             'conf_mat': cm,\n",
    "                             'class_report': report, \n",
    "                             'df_words_proba': df_words_prob,\n",
    "                             'words_test_doc_count': s_word_in_test_doc_count,\n",
    "                             'words_pred_pos_doc_count': s_word_in_pred_pos_doc_count}\n",
    "                             \n",
    "        \n",
    "output_filename= 'hold_out_results_under_over_ensemble_words_only.pickle'\n",
    "with open(output_filename, 'wb') as handle:                                     \n",
    "    pickle.dump(dict_years, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "t2= dt.now()\n",
    "print(t2)\n",
    "print(t2-t1)\n",
    "               \n",
    "#runtime 1hr56mins\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and store results for the baseline financial ratio (FIN) model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#not refactored\n",
    "\n",
    "#inputs\n",
    "random.seed(41)\n",
    "input_file = 'hold_out_fund_ratio_sets.pickle'\n",
    "output_filename = 'fund_ratio_hold_out_results.pickle'\n",
    "ratio = 5\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "label_years = list(map(lambda x: 'fund_h_out_' + str(x), years))\n",
    "over_sample_amount = [3]\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_',  'max_dd_1yr', 'ann_qcut']\n",
    "models = [GradientBoostingClassifier(random_state=41)]\n",
    "model_names = ['grad_boost']\n",
    "\n",
    "#create dictionary structure\n",
    "dict_results = {}\n",
    "for label in label_years:\n",
    "    dict_results.update({label: {}})\n",
    "    for model in model_names:\n",
    "        dict_results[label].update({model: {}})\n",
    "\n",
    "#populate dictionary\n",
    "d_h_out = pd.read_pickle(input_file)\n",
    "\n",
    "for label in label_years:\n",
    "    \n",
    "    df_train = d_h_out[label]['df_train_master']\n",
    "    df_test = d_h_out[label]['df_test_master']\n",
    "    \n",
    "    \n",
    "       \n",
    "#calculate previous year quartile rank\n",
    "    #join training and test to calculate annual quartile ranks\n",
    "    df_all = pd.concat([df_train, df_test])\n",
    "    df_all['year_'] = df_all['Filed_Date'].dt.year.values\n",
    "    \n",
    "    years = set(df_all['year_'].tolist())\n",
    "    years = sorted(list(years))\n",
    "    n_years =len(years)\n",
    "    \n",
    "    counter=0\n",
    "    for j in range(n_years-1):\n",
    "        current_year = years[j+1]\n",
    "        prev_year = years[j]\n",
    "        \n",
    "        mask_prev = df_all['year_'] == prev_year\n",
    "        df_prev = df_all[mask_prev]\n",
    "        df_prev['ann_qcut'] = pd.qcut(df_prev['max_dd_1yr'], q=[0,0.25,0.5,0.75,1],\n",
    "                                      labels=[4,3,2,1]).astype(int)\n",
    "        df_prev = df_prev[['ticker_','ann_qcut']]\n",
    "        mask_current = df_all['year_'] == current_year\n",
    "        df_current = df_all[mask_current]\n",
    "        df_current = df_current.merge(df_prev, on=['ticker_'], how='inner')\n",
    "        \n",
    "        if counter==0:\n",
    "            df_final = df_current\n",
    "        else:\n",
    "            df_final = pd.concat([df_final, df_current])\n",
    "        counter+=1\n",
    "    \n",
    "    #drop year_ column and sort ascending date\n",
    "    df_final = df_final.drop('year_', axis=1)\n",
    "    df_final = df_final.sort_values(by='Filed_Date')\n",
    "    \n",
    "    #split data bank into training and test sets\n",
    "    all_rows = df_all.shape[0]    \n",
    "    train_perc = df_train.shape[0] / df_all.shape[0] \n",
    "    updated_train_rows = int(train_perc * df_final.shape[0] // 1)\n",
    "    df_train = df_final.iloc[:updated_train_rows, :].reset_index(drop=True)\n",
    "    df_test = df_final.iloc[updated_train_rows:, :].reset_index(drop=True)\n",
    "\n",
    "    \n",
    "\n",
    "#Equal number algo (see helper function for comments)\n",
    "    mask_pos = df_train['max_dd_1yr'] < -0.8\n",
    "    df_year = df_train[['ticker_','Filed_Date']][mask_pos]\n",
    "    df_year['year'] = df_year['Filed_Date'].dt.year\n",
    "    df_pos_count = df_year['year'].value_counts()\n",
    "    \n",
    "    years = sorted(df_pos_count.index.tolist())\n",
    "    \n",
    "    df_train['year'] = df_train['Filed_Date'].dt.year\n",
    "\n",
    "    count=0\n",
    "    for year in years:\n",
    "    \n",
    "        mask_year = df_train['year']==year\n",
    "        df = df_train[mask_year]\n",
    "        mask_neg = df['max_dd_1yr'] >= -0.8 \n",
    "        df = df[mask_neg]\n",
    "        m = df.shape[0]\n",
    "        n = int(ratio*df_pos_count[year])\n",
    "    \n",
    "        random_idx = random.sample(range(0,m), n)\n",
    "        df = df.iloc[random_idx]\n",
    "        if count == 0:\n",
    "            df_final = df\n",
    "        else:\n",
    "            df_final = pd.concat([df_final,df])\n",
    "        count +=1    \n",
    "    \n",
    "    df_train = df_train.drop('year', axis=1)\n",
    "    df_neg = df_final.drop('year', axis=1)\n",
    "    df_pos = df_train[mask_pos]\n",
    "    \n",
    "    df_train = pd.concat([df_neg, df_pos])\n",
    "    df_train = df_train.sort_values(by='Filed_Date')\n",
    "    \n",
    "    \n",
    "     #define X and y dataframes\n",
    "    df_x_train = df_train.drop(x_drop_columns, axis=1)\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test.drop(x_drop_columns, axis=1)\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    #convert X and y arrays\n",
    "    X_train = df_x_train.values\n",
    "    y_train = df_y_train.values\n",
    "    X_test = df_x_test.values\n",
    "    y_test = df_y_test.values\n",
    "    \n",
    "    \n",
    "    #oversample (see helper function for comments)\n",
    "    for number in over_sample_amount:\n",
    "        \n",
    "        key_number = 'number'+ str(number)\n",
    "        idx_train_argsort= np.argsort(y_train)\n",
    "        n_pos = y_train.sum()\n",
    "        n_neg = y_train.shape[0] - n_pos\n",
    "    \n",
    "        idx_pos_prelim = idx_train_argsort[-n_pos:]\n",
    "        \n",
    "        n = int(number*n_pos)\n",
    "\n",
    "        idx_pos = np.random.choice(idx_pos_prelim, n)   \n",
    "        X_train_pos = X_train[idx_pos]\n",
    "        y_train_pos = y_train[idx_pos]\n",
    "        \n",
    "        idx_neg_prelim = idx_train_argsort[:n_neg]\n",
    "        random_idx = random.sample(range(0,n_neg), n)\n",
    "        idx_neg = idx_neg_prelim[random_idx]\n",
    "        X_train_neg = X_train[idx_neg]\n",
    "        y_train_neg = y_train[idx_neg]\n",
    "\n",
    "        X_train_balanced = np.concatenate((X_train_pos,X_train_neg), axis=0)\n",
    "        y_train_balanced = np.concatenate((y_train_pos,y_train_neg),axis=0)\n",
    "    \n",
    "    \n",
    "        #train model\n",
    "        for idx, model_func in enumerate(models):\n",
    "            model_name = model_names[idx]\n",
    "            model =model_func\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            y_pred = model.predict(X_test)\n",
    "    \n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            pos_recall = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "            neg_recall = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "            mh_recall =  2*neg_recall*pos_recall / (neg_recall + pos_recall)\n",
    "            report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        \n",
    "            print('mh_recall = ', mh_recall)\n",
    "            print('pos_recall = ', pos_recall)\n",
    "            print('neg_recall = ', neg_recall)\n",
    "        \n",
    "            df_y_result = df_test[['ticker_', 'Filed_Date']]\n",
    "            df_y_result['true_'] = y_test\n",
    "            df_y_result['pred_'] = y_pred\n",
    "    \n",
    "            dict_results[label][model_name] = {'df_y_result': df_y_result, 'class_report': report}\n",
    "            \n",
    "       \n",
    "with open(output_filename, 'wb') as handle:                                     \n",
    "    pickle.dump(dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test and store results for the market (MKT) model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)\n",
    "#not refactored\n",
    "\n",
    "#inputs\n",
    "random.seed(41)\n",
    "input_file = 'hold_out_fund_ratio_sets.pickle'\n",
    "output_filename = 'prev_quartile_only_hold_out_results.pickle'\n",
    "ratio = 5\n",
    "years = [2015, 2016, 2017, 2018, 2019]\n",
    "label_years = list(map(lambda x: 'fund_h_out_' + str(x), years))\n",
    "over_sample_amount = [3]\n",
    "x_drop_columns = ['Filed_Date', 'ticker_','sector_',  'max_dd_1yr']\n",
    "models = [GradientBoostingClassifier(random_state=41)]\n",
    "model_names = ['grad_boost']\n",
    "\n",
    "#create dictionary structure\n",
    "dict_results = {}\n",
    "for label in label_years:\n",
    "    dict_results.update({label: {}})\n",
    "    for model in model_names:\n",
    "        dict_results[label].update({model: {}})\n",
    "\n",
    "#read data into memory\n",
    "d_h_out = pd.read_pickle(input_file)\n",
    "\n",
    "#loop through holdout sets and populate dictionary\n",
    "for label in label_years:\n",
    "    \n",
    "    df_train = d_h_out[label]['df_train_master']\n",
    "    df_test = d_h_out[label]['df_test_master']\n",
    "    \n",
    "#calculate previous year quartile rank\n",
    "    #join training and test to calculate annual quartile ranks\n",
    "    df_all = pd.concat([df_train, df_test])\n",
    "    df_all['year_'] = df_all['Filed_Date'].dt.year.values\n",
    "    \n",
    "    years = set(df_all['year_'].tolist())\n",
    "    years = sorted(list(years))\n",
    "    n_years =len(years)\n",
    "    \n",
    "    counter=0\n",
    "    for j in range(n_years-1):\n",
    "        current_year = years[j+1]\n",
    "        prev_year = years[j]\n",
    "        \n",
    "        mask_prev = df_all['year_'] == prev_year\n",
    "        df_prev = df_all[mask_prev]\n",
    "        df_prev['ann_qcut'] = pd.qcut(df_prev['max_dd_1yr'], q=[0,0.25,0.5,0.75,1],\n",
    "                                      labels=[4,3,2,1]).astype(int)\n",
    "        df_prev = df_prev[['ticker_','ann_qcut']]\n",
    "        mask_current = df_all['year_'] == current_year\n",
    "        df_current = df_all[mask_current]\n",
    "        df_current = df_current.merge(df_prev, on=['ticker_'], how='inner')\n",
    "        \n",
    "        if counter==0:\n",
    "            df_final = df_current\n",
    "        else:\n",
    "            df_final = pd.concat([df_final, df_current])\n",
    "        counter+=1\n",
    "    \n",
    "    #drop year_ column and sort ascending date\n",
    "    df_final = df_final.drop('year_', axis=1)\n",
    "    df_final = df_final.sort_values(by='Filed_Date')\n",
    "    \n",
    "    #split data bank into training and test sets\n",
    "    all_rows = df_all.shape[0]    \n",
    "    train_perc = df_train.shape[0] / df_all.shape[0] \n",
    "    updated_train_rows = int(train_perc * df_final.shape[0] // 1)\n",
    "    df_train = df_final.iloc[:updated_train_rows, :].reset_index(drop=True)\n",
    "    df_test = df_final.iloc[updated_train_rows:, :].reset_index(drop=True)\n",
    "\n",
    "#Equal number algo (see helper function for comments)\n",
    "    mask_pos = df_train['max_dd_1yr'] < -0.8\n",
    "    df_year = df_train[['ticker_','Filed_Date']][mask_pos]\n",
    "    df_year['year'] = df_year['Filed_Date'].dt.year\n",
    "    df_pos_count = df_year['year'].value_counts()\n",
    "    \n",
    "    years = sorted(df_pos_count.index.tolist())\n",
    "    \n",
    "    df_train['year'] = df_train['Filed_Date'].dt.year\n",
    "\n",
    "    count=0\n",
    "    for year in years:\n",
    "    \n",
    "        mask_year = df_train['year']==year\n",
    "        df = df_train[mask_year]\n",
    "        mask_neg = df['max_dd_1yr'] >= -0.8 \n",
    "        df = df[mask_neg]\n",
    "        m = df.shape[0]\n",
    "        n = int(ratio*df_pos_count[year])\n",
    "    \n",
    "        random_idx = random.sample(range(0,m), n)\n",
    "        df = df.iloc[random_idx]\n",
    "        if count == 0:\n",
    "            df_final = df\n",
    "        else:\n",
    "            df_final = pd.concat([df_final,df])\n",
    "        count +=1    \n",
    "    \n",
    "    df_train = df_train.drop('year', axis=1)\n",
    "    df_neg = df_final.drop('year', axis=1)\n",
    "    df_pos = df_train[mask_pos]\n",
    "    \n",
    "    df_train = pd.concat([df_neg, df_pos])\n",
    "    df_train = df_train.sort_values(by='Filed_Date')\n",
    "    \n",
    "    \n",
    "    #define X and y dataframes\n",
    "    df_x_train = df_train['ann_qcut']\n",
    "    df_y_train= (df_train['max_dd_1yr'] <= -0.8)*1\n",
    "    df_x_test = df_test['ann_qcut']\n",
    "    df_y_test= (df_test['max_dd_1yr'] <= -0.8)*1\n",
    "\n",
    "    #convert X and y arrays\n",
    "    X_train = df_x_train.values\n",
    "    X_train = X_train.reshape(-1, 1)\n",
    "    y_train = df_y_train.values\n",
    "    X_test = df_x_test.values\n",
    "    X_test = X_test.reshape(-1, 1)\n",
    "    y_test = df_y_test.values\n",
    "    \n",
    "    #oversample (see helper function for comments)\n",
    "    idx_train_argsort= np.argsort(y_train)\n",
    "    n_pos = y_train.sum()\n",
    "    n_neg = y_train.shape[0] - n_pos\n",
    "    \n",
    "    idx_pos_prelim = idx_train_argsort[-n_pos:]\n",
    "    \n",
    "    for number in over_sample_amount:\n",
    "        \n",
    "        key_number = 'number'+ str(number)\n",
    "    \n",
    "        n = int(number*n_pos)\n",
    "\n",
    "        idx_pos = np.random.choice(idx_pos_prelim, n)   \n",
    "        X_train_pos = X_train[idx_pos]\n",
    "        y_train_pos = y_train[idx_pos]\n",
    "\n",
    "        idx_neg_prelim = idx_train_argsort[:n_neg]\n",
    "        random_idx = random.sample(range(0,n_neg), n)\n",
    "        idx_neg = idx_neg_prelim[random_idx]\n",
    "        X_train_neg = X_train[idx_neg]\n",
    "        y_train_neg = y_train[idx_neg]\n",
    "\n",
    "        X_train_balanced = np.concatenate((X_train_pos,X_train_neg), axis=0)\n",
    "        y_train_balanced = np.concatenate((y_train_pos,y_train_neg),axis=0)\n",
    "    \n",
    "    \n",
    "        #train model\n",
    "        for idx, model_func in enumerate(models):\n",
    "            model_name = model_names[idx]\n",
    "            model =model_func\n",
    "            model.fit(X_train_balanced, y_train_balanced)\n",
    "            y_pred = model.predict(X_test)\n",
    "    \n",
    "            cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "            pos_recall = cm[1,1] / (cm[1,0] + cm[1,1])\n",
    "            neg_recall = cm[0,0] / (cm[0,0] + cm[0,1])\n",
    "            mh_recall =  2*neg_recall*pos_recall / (neg_recall + pos_recall)\n",
    "            report = classification_report(y_test, y_pred,output_dict=True)\n",
    "        \n",
    "            print('mh_recall = ', mh_recall)\n",
    "            print('pos_recall = ', pos_recall)\n",
    "            print('neg_recall = ', neg_recall)\n",
    "        \n",
    "            df_y_result = df_test[['ticker_', 'Filed_Date']]\n",
    "            df_y_result['true_'] = y_test\n",
    "            df_y_result['pred_'] = y_pred\n",
    "    \n",
    "            dict_results[label][model_name] = {'df_y_result': df_y_result, 'class_report': report}\n",
    "            \n",
    "          \n",
    "with open(output_filename, 'wb') as handle:                                     \n",
    "    pickle.dump(dict_results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
